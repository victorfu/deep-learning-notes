# NLP

**Sequence to Sequence Learning with Neural Networks**. _Ilya Sutskever, Oriol Vinyals, Quoc V. Le_. [[1409.3215](https://arxiv.org/abs/1409.3215)]

**Attention Is All You Need**. _Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin_. NIPS 2017. [[1706.03762](https://arxiv.org/abs/1706.03762)]

**Generating Wikipedia by Summarizing Long Sequences**. _Peter J. Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, Noam Shazeer_. [[1801.10198](https://arxiv.org/abs/1801.10198)]

**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**. _Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova_. NAACL 2019. [[1810.04805](https://arxiv.org/pdf/1810.04805.pdf)] [[code & model](https://github.com/google-research/bert)]

**Well-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation**. _Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova_. Preprint. [[1908.08962](https://arxiv.org/pdf/1908.08962.pdf)]

**LLaMA: Open and Efficient Foundation Language Models**. _Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample_. [[2302.13971v1](https://arxiv.org/abs/2302.13971v1)]

## GPT (OpenAI)

**Improving Language Understanding by Generative Pre-Training**. _Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever_. Preprint. [[pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)] [[project](https://openai.com/blog/language-unsupervised/)] (**GPT**)

**Language Models are Unsupervised Multitask Learners**. _Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever_. Preprint. [[pdf](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)] [[code](https://github.com/openai/gpt-2)] (**GPT-2**)

**Language Models are Few-Shot Learners**. _Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei_. [[2005.14165](https://arxiv.org/abs/2005.14165)] (**GPT-3**)

**Training Language Models to Follow Instructions with Human Feedback**. _Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe_. [[2203.02155](https://arxiv.org/abs/2203.02155)] (**InstructGPT**)

# Computer Vision

**An Introduction to Variational Autoencoders**. _Diederik P. Kingma, Max Welling_. [[1906.02691](https://arxiv.org/abs/1906.02691)]

**Learning Transferable Visual Models From Natural Language Supervision**. _Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever_. [[2103.00020](https://arxiv.org/abs/2103.00020)]

## Diffusion Models

**Deep Unsupervised Learning using Nonequilibrium Thermodynamics**. _Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli_. [[1503.03585](https://arxiv.org/abs/1503.03585)]

**Generative Modeling by Estimating Gradients of the Data Distribution**. _Yang Song, Stefano Ermon_. [[1907.05600](https://arxiv.org/abs/1907.05600)]

**Momentum Contrast for Unsupervised Visual Representation Learning**. _Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick_. [[1911.05722](https://arxiv.org/abs/1911.05722)]

**Denoising Diffusion Probabilistic Models**. _Jonathan Ho, Ajay Jain, Pieter Abbeel_. [[2006.11239](https://arxiv.org/abs/2006.11239)]

**Denoising Diffusion Implicit Models**. _Jiaming Song, Chenlin Meng, Stefano Ermon_. [[2010.02502](https://arxiv.org/abs/2010.02502)]

**Score-Based Generative Modeling through Stochastic Differential Equations**. _Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole_. [[2011.13456](https://arxiv.org/abs/2011.13456)]

**Taming Transformers for High-Resolution Image Synthesis**. _Patrick Esser, Robin Rombach, Björn Ommer_. [[2012.09841](https://arxiv.org/abs/2012.09841)]

**Improved Denoising Diffusion Probabilistic Models**. _Alex Nichol, Prafulla Dhariwal_. [[2102.09672](https://arxiv.org/abs/2102.09672)]

**Diffusion Models Beat GANs on Image Synthesis**. _Prafulla Dhariwal, Alex Nichol_. [[2105.05233](https://arxiv.org/abs/2105.05233)]

**Variational Diffusion Models**. _Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho_. [[2107.00630](https://arxiv.org/abs/2107.00630)]

**High-Resolution Image Synthesis with Latent Diffusion Models**. _Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer_. [[2112.10752](https://arxiv.org/abs/2112.10752)]

**Hierarchical Text-Conditional Image Generation with CLIP Latents**. _Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen_. [[2204.06125](https://arxiv.org/abs/2204.06125)]

**Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding**. _Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, Mohammad Norouzi_. [[2205.11487](https://arxiv.org/abs/2205.11487)]

**Understanding Diffusion Models: A Unified Perspective**. _Calvin Luo_. [[2208.11970](https://arxiv.org/abs/2208.11970)]

**Diffusion Models: A Comprehensive Survey of Methods and Applications**. _Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Bin Cui, Ming-Hsuan Yang_. [[2209.00796](https://arxiv.org/abs/2209.00796)]

**Adding Conditional Control to Text-to-Image Diffusion Models**. _Lvmin Zhang, Maneesh Agrawala_. [[2302.05543](https://arxiv.org/abs/2302.05543)]

## Lee, Hugn-yi

**Basic Machine Learning**
[[ML2021-pdf](<https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/regression%20(v16).pdf>)]
[[ML2021-1](https://youtu.be/Ye018rCVvOo)]
[[ML2021-2](https://youtu.be/bHcJCp2Fyxs)]
[[ML2017](https://youtu.be/CXgbekl66jc)]

**Convolutional Neural Networks, CNN**
[[ML2021-pdf](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/cnn_v4.pdf)]
[[ML2021-9](https://youtu.be/OP5HcXJg2Aw)]
[[ML2016-pdf](<https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/CNN%20(v2).pdf>)]
[[ML2016](https://youtu.be/FrKWiRv254g)]

**Recurrent Neural Network, RNN**
[[pdf](<https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RNN%20(v2).pdf>)]
[[ML2016](https://youtu.be/xCGidAeyS4M)]
[[ML2016](https://youtu.be/rTqmWlnwz_0)]

**Self-attention**
[[ML2021-pdf](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/self_v7.pdf)]
[[ML2021-10](https://youtu.be/hYdO9CscNes)]
[[ML2021-11](https://youtu.be/gmsMY5kc-zw)]

**Transformer**
[[pdf](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/seq2seq_v9.pdf)]
[[ML2021-12](https://youtu.be/n9TlOhRjYoc)]
[[ML2021-13](https://youtu.be/N6aRv06iv2g)]

**Self-supervised Learning**
[[ML2021-pdf](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/bert_v8.pdf)]
[[ML2021-18](https://youtu.be/e422eloJ0W4)]
[[ML2021-19](https://youtu.be/gh0hewYkjgo)]
[[ML2021-20](https://youtu.be/ExXA05i8DEQ)]
[[ML2021-21](https://youtu.be/WY_E0Sd4K80)]

## Worth Reading

**_The Illustrated GPT-2_** [[link](https://jalammar.github.io/illustrated-gpt2/)]

**Neural Networks: Zero to Hero** [[link](https://karpathy.ai/zero-to-hero.html)]

**Let's build GPT: from scratch, in code, spelled out** [[link](https://youtu.be/kCc8FmEb1nY)]

**Generative Models** [[link](https://openai.com/blog/generative-models/)]

**Text and Code Embeddings** [[link](https://openai.com/blog/introducing-text-and-code-embeddings/)]

**Understanding dimensions in PyTorch** [[link](https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be)]

**Alien Dreams: An Emerging Art Scene** _Charlie Snell_ [[link](https://ml.berkeley.edu/blog/posts/clip-art/)]

**Improving Diffusion Models as an Alternative To GANs** [[link](https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/)]

**What are Diffusion Models?** [[link](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)]

**labml.ai Deep Learning Paper Implementations** [[link](https://github.com/labmlai/annotated_deep_learning_paper_implementations)]

---

**LoRA: Low-Rank Adaptation of Large Language Models**. _Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen_. [[2106.09685](https://arxiv.org/abs/2106.09685)]

**HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace**. _Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang_. [[2303.17580](https://arxiv.org/abs/2303.17580)]

**Segment Anything**. _Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick_. [[2304.02643](https://arxiv.org/abs/2304.02643)]

**Segment Everything Everywhere All at Once**. _Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Gao, Yong Jae Lee_. [[2304.06718](https://arxiv.org/abs/2304.06718)]
